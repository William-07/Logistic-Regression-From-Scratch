{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the sigmoid function from scratch\n",
    "def sigmoid_f(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "# Implement the hypothesis function from scratch\n",
    "def classifier_f(x, w, b):\n",
    "    linear_function = np.dot(x, w) + b\n",
    "    prediction_function = sigmoid_f(linear_function)\n",
    "    return prediction_function\n",
    "\n",
    "# Implement the entropy function as your cost function\n",
    "def binary_loss_f(y_true, y_prob, m):\n",
    "    cross_entropy = -sum(y_true * np.log(y_prob) + (1-y_true) * np.log(1-y_prob)) / m\n",
    "    return cross_entropy\n",
    "\n",
    "# Implement gradient descent for logistic regression\n",
    "def gradient_f(X, y_true, y_prob, lr, m, w, b):\n",
    "    dw = np.dot(X.T, (y_prob - y_true)) / m\n",
    "    db = sum(y_prob - y_true) / m\n",
    "    w = w - lr * dw\n",
    "    b = b - lr * db\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement an optimizer function for logistic regression\n",
    "def optimizer_f(x, y_true, iteration): \n",
    "    m = x.shape[0]\n",
    "    w = np.zeros(x.shape[1])\n",
    "    b = 0\n",
    "    for i in range(iteration):\n",
    "        y_prob = classifier_f(x, w, b)\n",
    "        loss = binary_loss_f(y_true, y_prob, m)\n",
    "        w, b = gradient_f(x, y_true, y_prob, 0.5, m, w, b)\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(e) The final equation is y = 15.52747 -1.31128 * mean radius -3.34398 * mean texture -1.39363 * mean perimeter -2.62534 * mean area -0.19934 * mean smoothness +1.32379 * mean compactness -4.57336 * mean concavity -6.28606 * mean concave points +0.08712 * mean symmetry +4.02317 * mean fractal dimension -6.32124 * radius error +0.43057 * texture error -4.55309 * perimeter error -3.89070 * area error -0.90427 * smoothness error +3.87414 * compactness error +1.21656 * concavity error +0.03104 * concave points error +1.29880 * symmetry error +2.44110 * fractal dimension error -5.19022 * worst radius -5.43374 * worst texture -4.41285 * worst perimeter -4.83622 * worst area -3.83927 * worst smoothness -0.34865 * worst compactness -3.18278 * worst concavity -5.15053 * worst concave points -4.14975 * worst symmetry -0.77157 * worst fractal dimension\n",
      "\n",
      "(f) The rank of coefficients:\n",
      "mean fractal dimension: 4.02317\n",
      "compactness error: 3.87414\n",
      "fractal dimension error: 2.44110\n",
      "mean compactness: 1.32379\n",
      "symmetry error: 1.29880\n",
      "concavity error: 1.21656\n",
      "texture error: 0.43057\n",
      "mean symmetry: 0.08712\n",
      "concave points error: 0.03104\n",
      "mean smoothness: -0.19934\n",
      "worst compactness: -0.34865\n",
      "worst fractal dimension: -0.77157\n",
      "smoothness error: -0.90427\n",
      "mean radius: -1.31128\n",
      "mean perimeter: -1.39363\n",
      "mean area: -2.62534\n",
      "worst concavity: -3.18278\n",
      "mean texture: -3.34398\n",
      "worst smoothness: -3.83927\n",
      "area error: -3.89070\n",
      "worst symmetry: -4.14975\n",
      "worst perimeter: -4.41285\n",
      "perimeter error: -4.55309\n",
      "mean concavity: -4.57336\n",
      "worst area: -4.83622\n",
      "worst concave points: -5.15053\n",
      "worst radius: -5.19022\n",
      "worst texture: -5.43374\n",
      "mean concave points: -6.28606\n",
      "radius error: -6.32124\n"
     ]
    }
   ],
   "source": [
    "def Q8():\n",
    "    # (a) Set the target column as Y variable\n",
    "    y = load_breast_cancer().target.reshape(-1, 1)\n",
    "    \n",
    "    # (b) Set all other numeric variables as X matrix\n",
    "    X = load_breast_cancer().data\n",
    "    \n",
    "    # (c) Apply 0-1 normalization on both X and Y\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    y = MinMaxScaler().fit_transform(y).reshape(-1)\n",
    "    \n",
    "    # (d) Run logistic regression by using the code written above\n",
    "    w, b = optimizer_f(X, y, 10000)\n",
    "    \n",
    "    # (e) Report the final equation obtained for logistic regression\n",
    "    coefs = {}\n",
    "    equation = '(e) The final equation is y = %.5f' % b\n",
    "    for i in range(len(w)):\n",
    "        coefs[load_breast_cancer().feature_names[i]] = w[i]\n",
    "        if w[i] >= 0:\n",
    "            equation += ' +%.5f * %s' % (w[i], load_breast_cancer().feature_names[i])\n",
    "        else:\n",
    "            equation += ' %.5f * %s' % (w[i], load_breast_cancer().feature_names[i])\n",
    "    print(equation)\n",
    "    \n",
    "    # (f) Rank coefficients from positive to negative\n",
    "    sorted_coefs = sorted(coefs.items(), key=lambda item: item[1], reverse=True)\n",
    "    print('\\n(f) The rank of coefficients:')\n",
    "    for key, value in sorted_coefs:\n",
    "        print('%s: %.5f' % (key, value))\n",
    "Q8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
